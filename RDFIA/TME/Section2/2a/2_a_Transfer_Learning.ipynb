{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbzBJ1m9FBBb"
      },
      "source": [
        "# Warning :\n",
        "# Do \"File -> Save a copy in Drive\" before you start modifying the notebook, otherwise your modifications will not be saved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO2MIqZcrhCQ"
      },
      "source": [
        "Avant de commencer le TP, vérifiez que vous êtes sur un environnement GPU et python 3 :\n",
        "\n",
        "Exécution -> Modifier le type d'exécution -> Type d'exécution = python2, Accélerateur matériel = GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hubU7zZbAz4a"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.svm import LinearSVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofov1WtQ64_p"
      },
      "source": [
        "# Partie 1 : Architecture VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eQjntfb5wI0"
      },
      "outputs": [],
      "source": [
        "#!wget https://github.com/cdancette/deep-learning-polytech-tp6-7/raw/master/tp8/imagenet_classes.pkl\n",
        "!wget https://github.com/rdfia/rdfia.github.io/raw/master/data/3-a/imagenet_classes.pkl\n",
        "\n",
        "# Bonus : Classifiez des exemples avec vgg16 et commentez le résultat dans votre rapport.\n",
        "!wget --content-disposition https://unsplash.com/photos/gKXKBY-C-Dk/download?force=true -O cat.jpg\n",
        "!wget --content-disposition https://unsplash.com/photos/qO-PIF84Vxg/download?force=true -O dog.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SASS6-LO6dmA"
      },
      "outputs": [],
      "source": [
        "cat = Image.open('cat.jpg')\n",
        "#dog = Image.open('dog.jpg')\n",
        "plt.imshow(cat)\n",
        "#plt.imshow(dog)\n",
        "# Ajoutez vos images\n",
        "# VOTRE CODE ICI pour le bonus:\n",
        "\n",
        "vgg16 = torchvision.models.vgg16(pretrained=True)\n",
        "\n",
        "imagenet_classes = pickle.load(open('imagenet_classes.pkl', 'rb')) # chargement des classes\n",
        "img = Image.open(\"cat.jpg\")\n",
        "img = img.resize((224, 224), Image.BILINEAR)\n",
        "img = np.array(img, dtype=np.float32) / 255\n",
        "img = img.transpose((2, 0, 1))\n",
        "\n",
        "img = np.expand_dims(img, 0)\n",
        "x = torch.Tensor(img)\n",
        "y = ... # TODO calcul forward\n",
        "y = y.numpy() # transformation en array numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQO8iQd26okS"
      },
      "source": [
        "# Partie 2: Transfer Learning avec VGG16 sur 15 Scene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vonhfnKF61bg"
      },
      "outputs": [],
      "source": [
        "#!wget https://github.com/cdancette/deep-learning-polytech-tp6-7/raw/master/tp8/15ScenesData.zip\n",
        "!wget https://github.com/rdfia/rdfia.github.io/raw/master/data/3-a/15ScenesData.zip\n",
        "\n",
        "!unzip 15ScenesData.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blP1Sj_0DXVd"
      },
      "outputs": [],
      "source": [
        "ls 15SceneData/test/bedroom/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooU4YUoYNxMa"
      },
      "outputs": [],
      "source": [
        "class VGG16relu17:\n",
        "  pass  # A COMPLÉTER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKmqYMPErn4p"
      },
      "outputs": [],
      "source": [
        "\n",
        "PRINT_INTERVAL = 50\n",
        "CUDA = True\n",
        "\n",
        "def get_dataset(batch_size, path):\n",
        "\n",
        "    # Cette fonction permet de recopier 3 fois une image qui\n",
        "    # ne serait que sur 1 channel (donc image niveau de gris)\n",
        "    # pour la \"transformer\" en image RGB. Utilisez la avec\n",
        "    # transform.Lambda\n",
        "    def duplicateChannel(img):\n",
        "        img = img.convert('L')\n",
        "        np_img = np.array(img, dtype=np.uint8)\n",
        "        np_img = np.dstack([np_img, np_img, np_img])\n",
        "        img = Image.fromarray(np_img, 'RGB')\n",
        "        return img\n",
        "\n",
        "    #####################\n",
        "    ## Votre code ici  ##\n",
        "    #####################\n",
        "    # Ajouter le pré-traitement\n",
        "    train_dataset = datasets.ImageFolder(path+'/train',\n",
        "        transform=transforms.Compose([ # Pré-traitement à faire\n",
        "            transforms.ToTensor()\n",
        "        ]))\n",
        "    val_dataset = datasets.ImageFolder(path+'/test',\n",
        "        transform=transforms.Compose([ # Pré-traitement à faire\n",
        "            transforms.ToTensor()\n",
        "        ]))\n",
        "    ####################\n",
        "    ##      FIN        #\n",
        "    ####################\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=CUDA, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=CUDA, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztOwrr0IrvGy"
      },
      "outputs": [],
      "source": [
        "def extract_features(data, model):\n",
        "    #####################\n",
        "    ## Votre code ici  ##\n",
        "    #####################\n",
        "    # init features matrices\n",
        "    X = None\n",
        "    y = None\n",
        "    ####################\n",
        "    ##      FIN        #\n",
        "    ####################\n",
        "\n",
        "    for i, (input, target) in enumerate(data):\n",
        "        if i % PRINT_INTERVAL == 0:\n",
        "            print('Batch {0:03d}/{1:03d}'.format(i, len(data)))\n",
        "        if CUDA:\n",
        "            input = input.cuda()\n",
        "        #####################\n",
        "        ## Votre code ici  ##\n",
        "        #####################\n",
        "        # Feature extraction à faire\n",
        "        X = None\n",
        "        y = None\n",
        "        ####################\n",
        "        ##      FIN        #\n",
        "        ####################\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def main(path=\"15SceneData\", batch_size=8):\n",
        "    print('Instanciation de VGG16')\n",
        "    vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "    print('Instanciation de VGG16relu7')\n",
        "    #####################\n",
        "    ## Votre code ici  ##\n",
        "    #####################\n",
        "    # Remplacer par le modèle par un réseau tronqué pour faire de la feature extraction\n",
        "    # On créera une nouvelle classe VGG16relu7 ici\n",
        "    model = vgg16\n",
        "    ####################\n",
        "    ##      FIN        #\n",
        "    ####################\n",
        "\n",
        "    model.eval()\n",
        "    if CUDA: # si on fait du GPU, passage en CUDA\n",
        "        cudnn.benchmark = True\n",
        "        model = model.cuda()\n",
        "\n",
        "    # On récupère les données\n",
        "    print('Récupération des données')\n",
        "    train, test = get_dataset(batch_size, path)\n",
        "\n",
        "    # Extraction des features\n",
        "    print('Feature extraction')\n",
        "    X_train, y_train = extract_features(train, model)\n",
        "    X_test, y_test = extract_features(test, model)\n",
        "\n",
        "    #####################\n",
        "    ## Votre code ici  ##\n",
        "    #####################\n",
        "    # Apprentissage et évaluation des SVM à faire\n",
        "    print('Apprentissage des SVM')\n",
        "    accuracy = 0\n",
        "    ####################\n",
        "    ##      FIN        #\n",
        "    ####################\n",
        "    print('Accuracy = %f' % accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMh4ih-QvjOd"
      },
      "outputs": [],
      "source": [
        "main(\"15SceneData\", 8)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}