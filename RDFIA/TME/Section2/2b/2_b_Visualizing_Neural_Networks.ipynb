{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "f5J96zex-R3G"
      },
      "source": [
        "# 2-b: Visualizing Neural Networks\n",
        "\n",
        "#### To keep your modifications in case you want to come back later to this colab, do *File -> Save a copy in Drive*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du3JMqfh-R3N"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import random\n",
        "import numpy as np\n",
        "from scipy.ndimage.filters import gaussian_filter1d\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'viridis'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO1mXODA-R3Z"
      },
      "source": [
        "## Functions and useful variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92UaaZxw-R3c"
      },
      "source": [
        "SQUEEZENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
        "SQUEEZENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
        "\n",
        "def preprocess(img, size=224):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=SQUEEZENET_MEAN.tolist(),\n",
        "                    std=SQUEEZENET_STD.tolist()),\n",
        "        transforms.Lambda(lambda x: x[None]),  # add one dimension\n",
        "    ])\n",
        "    return transform(img)\n",
        "\n",
        "def deprocess(img, should_rescale=True):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Lambda(lambda x: x[0]),\n",
        "        transforms.Normalize(mean=[0, 0, 0], std=(1.0 / SQUEEZENET_STD).tolist()),\n",
        "        transforms.Normalize(mean=(-SQUEEZENET_MEAN).tolist(), std=[1, 1, 1]),\n",
        "        transforms.Lambda(rescale) if should_rescale else transforms.Lambda(lambda x: x),\n",
        "        transforms.ToPILImage(),\n",
        "    ])\n",
        "    return transform(img)\n",
        "\n",
        "def rescale(x):\n",
        "    low, high = x.min(), x.max()\n",
        "    x_rescaled = (x - low) / (high - low)\n",
        "    return x_rescaled\n",
        "\n",
        "def blur_image(X, sigma=1):\n",
        "    X_np = X.cpu().clone().detach().numpy()\n",
        "    X_np = gaussian_filter1d(X_np, sigma, axis=2)\n",
        "    X_np = gaussian_filter1d(X_np, sigma, axis=3)\n",
        "    X.copy_(torch.Tensor(X_np).type_as(X))\n",
        "    return X\n",
        "\n",
        "def jitter(X, ox, oy):\n",
        "    \"\"\"\n",
        "    Helper function to randomly jitter an image.\n",
        "\n",
        "    Inputs\n",
        "    - X: PyTorch Tensor of shape (N, C, H, W)\n",
        "    - ox, oy: Integers giving number of pixels to jitter along W and H axes\n",
        "\n",
        "    Returns: A new PyTorch Tensor of shape (N, C, H, W)\n",
        "    \"\"\"\n",
        "    if ox != 0:\n",
        "        left = X[:, :, :, :-ox]\n",
        "        right = X[:, :, :, -ox:]\n",
        "        X = torch.cat([right, left], dim=3)\n",
        "    if oy != 0:\n",
        "        top = X[:, :, :-oy]\n",
        "        bottom = X[:, :, -oy:]\n",
        "        X = torch.cat([bottom, top], dim=2)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxYQoVhx-R3k"
      },
      "source": [
        "## Load the model\n",
        "\n",
        "For this TME, we will use the Squeezenet model which is a light model pre-trained on ImageNet. This model will be frozen: the goal is not to modify or train the weights but to study them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPwWLUAD-R3n"
      },
      "source": [
        "# Load the model\n",
        "model = torchvision.models.squeezenet1_1(pretrained=True)\n",
        "\n",
        "# Model in test mode\n",
        "model.eval()\n",
        "\n",
        "# Freeze the weights\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF3hHqWr-R3w"
      },
      "source": [
        "## Load example images\n",
        "\n",
        "This will fill the variables `X, y, class_names` with 25 examples from the validation set of ImageNet. `X` containes the images, `y` the class index of each image, and `class_names` a dictionary giving the class name from its index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkg4v3wq_v58"
      },
      "source": [
        "# Download data\n",
        "#!wget https://github.com/cdancette/deep-learning-polytech-tp6-7/raw/master/tp9/imagenet_val_25.npz\n",
        "!wget https://github.com/rdfia/rdfia.github.io/raw/master/data/3-b/imagenet_val_25.npz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps-orUXv-R3y"
      },
      "source": [
        "f = np.load(\"imagenet_val_25.npz\", allow_pickle=True)\n",
        "X, y, class_names = f[\"X\"], f[\"y\"], f[\"label_map\"].item()\n",
        "class_names_to_id = {name: id for id, name in class_names.items()}\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "for i in range(24):\n",
        "    plt.subplot(4, 6, i + 1)\n",
        "    plt.imshow(X[i])\n",
        "    plt.title(class_names[y[i]])\n",
        "    plt.axis('off')\n",
        "plt.gcf().tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezmefelP-R35"
      },
      "source": [
        "# Saliency Maps\n",
        "\n",
        "Calculate the saliency map for 5 examples out of the 25 loaded ones following the instructions of the TP guide.\n",
        "\n",
        "**Hint :** To choose 1 particular value in each row of a matrix, you can do this:\n",
        "\n",
        "```python\n",
        "x = torch.Tensor([[0.1, 0.0, 0.5, 0.1, 0.1],\n",
        "                  [0.0, 0.1, 0.0, 0.6, 0.2],\n",
        "                  [0.7, 0.1, 0.1, 0.3, 0.0]])\n",
        "x[np.arange(3), [2, 3, 0]]\n",
        "# 0.5000\n",
        "# 0.6000\n",
        "# 0.7000\n",
        "#[torch.FloatTensor of size 3]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucHO_isQ-R37"
      },
      "source": [
        "def compute_saliency_maps(X, y, model):\n",
        "    \"\"\"\n",
        "    Compute a class saliency map using the model for images X and labels y.\n",
        "\n",
        "    Input:\n",
        "    - X: Input images; Tensor of shape (N, 3, H, W)\n",
        "    - y: Labels for X; LongTensor of shape (N,)\n",
        "    - model: A pretrained CNN that will be used to compute the saliency map.\n",
        "\n",
        "    Returns:\n",
        "    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n",
        "    images.\n",
        "    \"\"\"\n",
        "    # activate gradients on X\n",
        "    X.requires_grad = True\n",
        "    saliency = None\n",
        "    ##############################################################################\n",
        "    # TODO: Implement this function. Perform a forward and backward pass through #\n",
        "    # the model to compute the gradient of the correct class score with respect  #\n",
        "    # to each input image.                                                       #\n",
        "    # You first want to extract the logits for the correct  scores (not the loss),#\n",
        "    # and then compute the gradients with a backward pass.                       #\n",
        "    ##############################################################################\n",
        "    pass\n",
        "    ##############################################################################\n",
        "    #                             END OF YOUR CODE                               #\n",
        "    ##############################################################################\n",
        "    return saliency"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBeE3JFR-R4C"
      },
      "source": [
        "Test your code with the following function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "yHae91n0-R4E"
      },
      "source": [
        "def show_saliency_maps(X, y, model):\n",
        "    # Convert X and y from numpy arrays to Torch Tensors\n",
        "    X_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in X], dim=0)\n",
        "    y_tensor = torch.LongTensor(y)\n",
        "\n",
        "    # Compute saliency maps for images in X\n",
        "    saliency = compute_saliency_maps(X_tensor, y_tensor, model)\n",
        "\n",
        "    # Convert the saliency map from Torch Tensor to numpy array and show images\n",
        "    # and saliency maps together.\n",
        "    saliency = saliency.numpy()\n",
        "    N = X.shape[0]\n",
        "    for i in range(N):\n",
        "        plt.subplot(2, N, i + 1)\n",
        "        plt.imshow(X[i])\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y[i]])\n",
        "        plt.subplot(2, N, N + i + 1)\n",
        "        plt.imshow(saliency[i], cmap=plt.cm.hot)\n",
        "        plt.axis('off')\n",
        "        plt.gcf().set_size_inches(12, 5)\n",
        "    plt.show()\n",
        "\n",
        "for i in range(5): # range(5) pour tester toutes les images\n",
        "    show_saliency_maps(X[5*i:5*i+5], y[5*i:5*i+5], model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOESl8Gj-R4L"
      },
      "source": [
        "# Adversarial Examples (Fooling Images)\n",
        "\n",
        "Write the code to calculate an image such that it will be classified in a `target_y` different from the real class (by modifying the image and not the network parameters). See the TP guide for instructions.\n",
        "\n",
        "**The first two blocks will allow you to perform tests in an interactive way** to write and test your code. Once your code seems to work, complete the function in the 3rd block and test on various images in the 4th block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQNT2aP1-R4N"
      },
      "source": [
        "# Initialize tests\n",
        "X_tensor = torch.Tensor(preprocess(Image.fromarray(X[0])))\n",
        "target_y = class_names_to_id['stingray']  # Desired class\n",
        "X_fooling = X_tensor.clone()\n",
        "X_fooling.requires_grad = True\n",
        "learning_rate = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "b2hrwK0S-R4T"
      },
      "source": [
        "# TODO write your code to test here\n",
        "\n",
        "# Visualize the image X_folling and its modifications\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(np.asarray(deprocess(X_fooling.clone())).astype(np.uint8))\n",
        "plt.title(\"Image X_fooling\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(np.asarray(deprocess(10* (X_fooling - X_tensor), should_rescale=False)))\n",
        "plt.title(\"Magnified difference with X_tensor (x10)\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMWT0YVj-R4Z"
      },
      "source": [
        "def make_fooling_image(X, target_y, model):\n",
        "    \"\"\"\n",
        "    Generate a fooling image that is close to X, but that the model classifies\n",
        "    as target_y.\n",
        "\n",
        "    Inputs:\n",
        "    - X: Input image; Tensor of shape (1, 3, 224, 224)\n",
        "    - target_y: An integer in the range [0, 1000)\n",
        "    - model: A pretrained CNN\n",
        "\n",
        "    Returns:\n",
        "    - X_fooling: An image that is close to X, but that is classifed as target_y\n",
        "    by the model.\n",
        "    \"\"\"\n",
        "    # Initialize our fooling image to the input image, enable gradients.\n",
        "    X_fooling = X.clone()\n",
        "    X_fooling.requires_grad = True\n",
        "\n",
        "    learning_rate = 1\n",
        "    ##############################################################################\n",
        "    # TODO: Generate a fooling image X_fooling that the model will classify as   #\n",
        "    # the class target_y. You should perform gradient ascent on the score of the #\n",
        "    # target class, stopping when the model is fooled.                           #\n",
        "    # When computing an update step, first normalize the gradient:               #\n",
        "    #   dX = learning_rate * grad / ||grad||_2                                   #\n",
        "    #                                                                            #\n",
        "    # You should write a training loop.                                          #\n",
        "    #                                                                            #\n",
        "    # HINT: For most examples, you should be able to generate a fooling image    #\n",
        "    # in fewer than 100 iterations of gradient ascent.                           #\n",
        "    # You can print your progress over iterations to check your algorithm.       #\n",
        "    # HINT: Remember to reset gradients at each step                             #\n",
        "    # HINT: update shouldn't be tracked by the autograd (see for example         #\n",
        "    # https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_autograd.html#sphx-glr-beginner-examples-autograd-two-layer-net-autograd-py #\n",
        "    ##############################################################################\n",
        "    pass\n",
        "    ##############################################################################\n",
        "    #                             END OF YOUR CODE                               #\n",
        "    ##############################################################################\n",
        "    return X_fooling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LBRDXnEQ-R4g"
      },
      "source": [
        "# Index of the image to modify and the target class\n",
        "idx = 1\n",
        "target_y = class_names_to_id['stingray']\n",
        "\n",
        "# Preparation of tensor X and it's \"fooling\" version\n",
        "X_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in X], dim=0)\n",
        "X_fooling = make_fooling_image(X_tensor[idx:idx+1], target_y, model)\n",
        "\n",
        "# Check the predicted class\n",
        "scores = model(X_fooling)\n",
        "assert target_y == scores.data.max(1)[1][0], 'The model is not fooled!'\n",
        "\n",
        "# Display\n",
        "X_fooling_np = deprocess(X_fooling.clone())\n",
        "X_fooling_np = np.asarray(X_fooling_np).astype(np.uint8)\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.imshow(X[idx])\n",
        "plt.title(class_names[y[idx]])\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(X_fooling_np)\n",
        "plt.title(class_names[target_y])\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "X_pre = preprocess(Image.fromarray(X[idx]))\n",
        "diff = np.asarray(deprocess(X_fooling - X_pre, should_rescale=False))\n",
        "plt.imshow(diff)\n",
        "plt.title('Difference')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "diff = np.asarray(deprocess(10 * (X_fooling - X_pre), should_rescale=False))\n",
        "plt.imshow(diff)\n",
        "plt.title('Magnified difference (10x)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.gcf().set_size_inches(12, 5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hXRsKrmiExt"
      },
      "source": [
        "### Bonus : test with different input images and different target classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pArNLZ4p-R4k"
      },
      "source": [
        "# Class visualization\n",
        "\n",
        "Write the code which generates an image maximizing the score of a class, subject to a certain number of regularizations. See the TP guide for details.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_7MJCB5-R4m"
      },
      "source": [
        "def create_class_visualization(target_y, model, dtype, init_img=None, l2_reg=1e-3, learning_rate=5,\n",
        "                               num_iterations=200, blur_every=10, max_jitter=16, show_every=25):\n",
        "    \"\"\"\n",
        "    Generate an image to maximize the score of target_y under a pretrained model.\n",
        "\n",
        "    Inputs:\n",
        "    - target_y: Integer in the range [0, 1000) giving the index of the class\n",
        "    - model: A pretrained CNN that will be used to generate the image\n",
        "    - dtype: Torch datatype to use for computations\n",
        "\n",
        "    Keyword arguments:\n",
        "    - init_img: Initial image to use (if None, will be random)\n",
        "    - l2_reg: Strength of L2 regularization on the image\n",
        "    - learning_rate: How big of a step to take\n",
        "    - num_iterations: How many iterations to use\n",
        "    - blur_every: How often to blur the image as an implicit regularizer\n",
        "    - max_jitter: How much to gjitter the image as an implicit regularizer\n",
        "    - show_every: How often to show the intermediate result\n",
        "    \"\"\"\n",
        "    model.type(dtype)\n",
        "\n",
        "    # Randomly initialize the image as a PyTorch Tensor\n",
        "    if init_img is None:\n",
        "        img = torch.randn(1, 3, 224, 224).mul_(1.0).type(dtype).detach()\n",
        "    else:\n",
        "        img = init_img.clone().mul_(1.0).type(dtype).detach()\n",
        "    img.requires_grad = True\n",
        "\n",
        "    for t in range(num_iterations):\n",
        "        # Randomly jitter the image a bit; this gives slightly nicer results\n",
        "        ox, oy = random.randint(0, max_jitter), random.randint(0, max_jitter)\n",
        "        img = (jitter(img, ox, oy)).clone().detach()\n",
        "        img.requires_grad = True\n",
        "\n",
        "        ########################################################################\n",
        "        # - TODO: Use the model to compute the gradient of the score for the   #\n",
        "        # class target_y with respect to the pixels of the image, and make a   #\n",
        "        # gradient step on the image using the learning rate. Don't forget the #\n",
        "        # L2 regularization term!                                              #\n",
        "        # - Be very careful about the signs of elements in your code.          #\n",
        "        # - Advice: compute backward on the raw logits (not the loss), it      #\n",
        "        # works better                                                         #\n",
        "        ########################################################################\n",
        "        pass\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "        # Undo the random jitter\n",
        "        img.data.copy_(jitter(img, -ox, -oy))\n",
        "        img = img.clone()\n",
        "\n",
        "        # As regularizer, clamp and periodically blur the image\n",
        "        for c in range(3):\n",
        "            lo = float(-SQUEEZENET_MEAN[c] / SQUEEZENET_STD[c])\n",
        "            hi = float((1.0 - SQUEEZENET_MEAN[c]) / SQUEEZENET_STD[c])\n",
        "            img[:, c].clamp_(min=lo, max=hi)\n",
        "        if t % blur_every == 0:\n",
        "            blur_image(img, sigma=0.5)\n",
        "\n",
        "        # Periodically show the image\n",
        "        if t == 0 or (t + 1) % show_every == 0 or t == num_iterations - 1:\n",
        "            plt.imshow(deprocess(img.clone().cpu()))\n",
        "            class_name = class_names[target_y]\n",
        "            plt.title('%s\\nIteration %d / %d' % (class_name, t + 1, num_iterations))\n",
        "            plt.gcf().set_size_inches(4, 4)\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "    return deprocess(img.cpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgi-dnbf-R4s"
      },
      "source": [
        "Test with various classes and starting from random noise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nlgvIGSW-R4u"
      },
      "source": [
        "dtype = torch.FloatTensor\n",
        "# dtype = torch.cuda.FloatTensor # Uncomment this to use GPU\n",
        "model.type(dtype)\n",
        "\n",
        "target_y = 76 # Tarantula\n",
        "# target_y = 78 # Tick\n",
        "# target_y = 187 # Yorkshire Terrier\n",
        "# target_y = 683 # Oboe\n",
        "# target_y = 366 # Gorilla\n",
        "# target_y = 604 # Hourglass\n",
        "# target_y = 113 # Snail\n",
        "# target_y = np.random.randint(1000) # Classe al√©atoire\n",
        "out = create_class_visualization(target_y, model, dtype, show_every=25, num_iterations=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-ITjwDc-R4z"
      },
      "source": [
        "Test by starting from an image from ImageNet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BnCwzB1-R41"
      },
      "source": [
        "# Initialize test\n",
        "img_ind = 0\n",
        "\n",
        "target_y = 113 # snail\n",
        "X_tensor = torch.Tensor(preprocess(Image.fromarray(X[img_ind])))\n",
        "out = create_class_visualization(target_y, model, dtype, init_img=X_tensor, show_every=25, num_iterations=200)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}