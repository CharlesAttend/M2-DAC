{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading datasets...\n",
      "INFO:root:Vocabulary size: 42932\n",
      "INFO:root:Tags size: 18\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import torchmetrics as tm\n",
    "from datamaestro import prepare_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from typing import List\n",
    "import time\n",
    "from icecream import ic\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "ds = prepare_dataset(\"org.universaldependencies.french.gsd\")\n",
    "\n",
    "\n",
    "# Format de sortie décrit dans\n",
    "# https://pypi.org/project/conllu/\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"Permet de gérer un vocabulaire.\n",
    "\n",
    "    En test, il est possible qu'un mot ne soit pas dans le\n",
    "    vocabulaire : dans ce cas le token \"__OOV__\" est utilisé.\n",
    "    Attention : il faut tenir compte de cela lors de l'apprentissage !\n",
    "\n",
    "    Utilisation:\n",
    "\n",
    "    - en train, utiliser v.get(\"blah\", adding=True) pour que le mot soit ajouté\n",
    "      automatiquement s'il n'est pas connu\n",
    "    - en test, utiliser v[\"blah\"] pour récupérer l'ID du mot (ou l'ID de OOV)\n",
    "    \"\"\"\n",
    "\n",
    "    OOVID = 1\n",
    "    PAD = 0\n",
    "\n",
    "    def __init__(self, oov: bool):\n",
    "        \"\"\"oov : autorise ou non les mots OOV\"\"\"\n",
    "        self.oov = oov\n",
    "        self.id2word = [\"PAD\"]\n",
    "        self.word2id = {\"PAD\": Vocabulary.PAD}\n",
    "        if oov:\n",
    "            self.word2id[\"__OOV__\"] = Vocabulary.OOVID\n",
    "            self.id2word.append(\"__OOV__\")\n",
    "\n",
    "    def __getitem__(self, word: str):\n",
    "        if self.oov:\n",
    "            return self.word2id.get(word, Vocabulary.OOVID)\n",
    "        return self.word2id[word]\n",
    "\n",
    "    def get(self, word: str, adding=True):\n",
    "        try:\n",
    "            return self.word2id[word]\n",
    "        except KeyError:\n",
    "            if adding:\n",
    "                wordid = len(self.id2word)\n",
    "                self.word2id[word] = wordid\n",
    "                self.id2word.append(word)\n",
    "                return wordid\n",
    "            if self.oov:\n",
    "                return Vocabulary.OOVID\n",
    "            raise\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id2word)\n",
    "\n",
    "    def getword(self, idx: int):\n",
    "        if idx < len(self):\n",
    "            return self.id2word[idx]\n",
    "        return None\n",
    "\n",
    "    def getwords(self, idx: List[int]):\n",
    "        return [self.getword(i) for i in idx]\n",
    "\n",
    "\n",
    "class TaggingDataset:\n",
    "    def __init__(self, data, words: Vocabulary, tags: Vocabulary, adding=True):\n",
    "        self.sentences = []\n",
    "\n",
    "        for s in data:\n",
    "            self.sentences.append(\n",
    "                (\n",
    "                    [words.get(token[\"form\"], adding) for token in s],\n",
    "                    [tags.get(token[\"upostag\"], adding) for token in s],\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.sentences[ix]\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate using pad_sequence\"\"\"\n",
    "    return tuple(\n",
    "        pad_sequence([torch.LongTensor(b[j]) for b in batch]) for j in range(2)\n",
    "    )\n",
    "\n",
    "\n",
    "logging.info(\"Loading datasets...\")\n",
    "words = Vocabulary(True)\n",
    "tags = Vocabulary(False)\n",
    "train_data = TaggingDataset(ds.train, words, tags, True)\n",
    "dev_data = TaggingDataset(ds.validation, words, tags, True)\n",
    "test_data = TaggingDataset(ds.test, words, tags, False)\n",
    "\n",
    "\n",
    "logging.info(\"Vocabulary size: %d\", len(words))\n",
    "logging.info(\"Tags size: %d\", len(tags))\n",
    "BATCH_SIZE = 100\n",
    "BATCH_SIZE = 32\n",
    "LEN_WORDS = len(words)\n",
    "LEN_TAG = len(tags)\n",
    "train_loader = DataLoader(\n",
    "    train_data, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "dev_loader = DataLoader(dev_data, collate_fn=collate_fn, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_data, collate_fn=collate_fn, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]ic| input.size(): torch.Size([59, 32])\n",
      "ic| target.size(): torch.Size([59, 32])\n",
      "ic| output.size(): torch.Size([59, 32, 64])\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [59, 64], got [59, 32]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/charles/M2-DAC/AMAL/TME/TME6/src/tagging.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/charles/M2-DAC/AMAL/TME/TME6/src/tagging.ipynb#X10sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/charles/M2-DAC/AMAL/TME/TME6/src/tagging.ipynb#X10sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(nb_epoch)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/charles/M2-DAC/AMAL/TME/TME6/src/tagging.ipynb#X10sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     mean_loss, acc_test \u001b[39m=\u001b[39m train_epoch(train_loader, model, loss_fn, optimizer, cuda\u001b[39m=\u001b[39;49mcuda)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/charles/M2-DAC/AMAL/TME/TME6/src/tagging.ipynb#X10sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     acc_test \u001b[39m=\u001b[39m evaluate(test_loader, model, loss_fn, cuda\u001b[39m=\u001b[39mcuda)\n",
      "\u001b[1;32m/home/charles/M2-DAC/AMAL/TME/TME6/src/tagging.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/charles/M2-DAC/AMAL/TME/TME6/src/tagging.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m output \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/charles/M2-DAC/AMAL/TME/TME6/src/tagging.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m ic(output\u001b[39m.\u001b[39msize())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/charles/M2-DAC/AMAL/TME/TME6/src/tagging.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/charles/M2-DAC/AMAL/TME/TME6/src/tagging.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss_list\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/charles/M2-DAC/AMAL/TME/TME6/src/tagging.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# backward if we are training\u001b[39;00m\n",
      "File \u001b[0;32m~/M2-DAC/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/M2-DAC/.venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m~/M2-DAC/.venv/lib/python3.11/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [59, 64], got [59, 32]"
     ]
    }
   ],
   "source": [
    "def train_epoch(loader, model, loss_fn, optimizer, logger=None, cuda=False, num_classes=18):\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    acc = tm.classification.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "    for input, target in loader:\n",
    "        if cuda:  # only with GPU, and not with CPU\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        ic(input.size())\n",
    "        ic(target.size())\n",
    "        output = model(input)\n",
    "        ic(output.size())\n",
    "        loss = loss_fn(output, target)\n",
    "        loss_list.append(loss.item)\n",
    "        # backward if we are training\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return np.array(loss_list).mean()\n",
    "\n",
    "\n",
    "def evaluate(loader, model, loss_fn, cuda=False, num_classes=18):\n",
    "    model.eval()\n",
    "    acc = tm.classification.Accuracy(task=\"multiclass\" , num_classes=num_classes)\n",
    "    for input, target in loader:\n",
    "        if cuda:  # only with GPU, and not with CPU\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        # forward\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim,\n",
    "        hidden_size,\n",
    "        vocab_size,\n",
    "        tag_size,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_size)\n",
    "        self.f_h = nn.Linear(hidden_size, tag_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        h, (_, _) = self.rnn(x)\n",
    "        return h\n",
    "\n",
    "    def decode(h):\n",
    "        return self.f_h(h)\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "nb_epoch = 10\n",
    "\n",
    "\n",
    "model = Model(32, 64, LEN_WORDS, LEN_TAG)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in tqdm(range(nb_epoch)):\n",
    "    mean_loss, acc_test = train_epoch(train_loader, model, loss_fn, optimizer, cuda=cuda)\n",
    "    acc_test = evaluate(test_loader, model, loss_fn, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([83, 32])\n",
      "torch.Size([83, 32])\n",
      "['Mais', 'le', 'courageux', 'garçon', 'devra', 'revenir', 'avant', 'le', 'crépuscule', '...', 'alors', 'que', \"l'\", 'orage', 'qui', \"s'\", 'approche', 'lui', 'mettra', 'des', 'bâtons', 'dans', 'les', 'roues', '.', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "tensor([13,  1,  3,  2,  5,  5,  7,  1,  2, 10,  6,  8,  1,  2,  9,  9,  5,  9,\n",
      "         5,  1,  2,  7,  1,  2, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    print(x.size())\n",
    "    print(y.size())\n",
    "    for i in range(x.size(1)):\n",
    "        print(words.getwords(x[:, i]))\n",
    "        break\n",
    "    for i in range(y.size(1)):\n",
    "        print(y[:, i])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1])\n",
      "torch.Size([6, 1])\n",
      "['Il', 'fut', 'un', 'antisémite', 'enragé', '.']\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    print(x.size())\n",
    "    print(y.size())\n",
    "    print(words.getwords(x))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
