{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(-5, 5, 500), np.linspace(-5, 5, 500))\n",
    "# Generate normal (not abnormal) training observations\n",
    "X = 0.3 * np.random.randn(100, 2)\n",
    "X_train = np.r_[X + 2, X - 2]\n",
    "# Generate new normal (not abnormal) observations\n",
    "X = 0.3 * np.random.randn(20, 2)\n",
    "X_test = np.r_[X + 2, X - 2]\n",
    "# Generate some abnormal novel observations\n",
    "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
    "\n",
    "# fit the model for novelty detection (novelty=True)\n",
    "clf = LocalOutlierFactor(n_neighbors=20, novelty=True, contamination=0.1)\n",
    "clf.fit(X_train)\n",
    "# DO NOT use predict, decision_function and score_samples on X_train as this\n",
    "# would give wrong results but only on new unseen data (not used in X_train),\n",
    "# e.g. X_test, X_outliers or the meshgrid\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_outliers = clf.predict(X_outliers)\n",
    "n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "n_error_outliers = y_pred_outliers[y_pred_outliers == 1].size\n",
    "\n",
    "# plot the learned frontier, the points, and the nearest vectors to the plane\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.title(\"Novelty Detection with LOF\")\n",
    "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.PuBu)\n",
    "a = plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors=\"darkred\")\n",
    "plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors=\"palevioletred\")\n",
    "\n",
    "s = 40\n",
    "b1 = plt.scatter(X_train[:, 0], X_train[:, 1], c=\"white\", s=s, edgecolors=\"k\")\n",
    "b2 = plt.scatter(X_test[:, 0], X_test[:, 1], c=\"blueviolet\", s=s, edgecolors=\"k\")\n",
    "c = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c=\"gold\", s=s, edgecolors=\"k\")\n",
    "plt.axis(\"tight\")\n",
    "plt.xlim((-5, 5))\n",
    "plt.ylim((-5, 5))\n",
    "plt.legend(\n",
    "    [a.collections[0], b1, b2, c],\n",
    "    [\n",
    "        \"learned frontier\",\n",
    "        \"training observations\",\n",
    "        \"new regular observations\",\n",
    "        \"new abnormal observations\",\n",
    "    ],\n",
    "    loc=\"upper left\",\n",
    "    prop=matplotlib.font_manager.FontProperties(size=11),\n",
    ")\n",
    "plt.xlabel(\n",
    "    \"errors novel regular: %d/40 ; errors novel abnormal: %d/40\"\n",
    "    % (n_error_test, n_error_outliers)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "font = {\"weight\": \"normal\", \"size\": 15}\n",
    "\n",
    "matplotlib.rc(\"font\", **font)\n",
    "\n",
    "random_state = 42\n",
    "rng = np.random.RandomState(random_state)\n",
    "\n",
    "# Generate train data\n",
    "X = 0.3 * rng.randn(500, 2)\n",
    "X_train = np.r_[X + 2, X - 2]\n",
    "# Generate some regular novel observations\n",
    "X = 0.3 * rng.randn(20, 2)\n",
    "X_test = np.r_[X + 2, X - 2]\n",
    "# Generate some abnormal novel observations\n",
    "X_outliers = rng.uniform(low=-4, high=4, size=(20, 2))\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(-4.5, 4.5, 50), np.linspace(-4.5, 4.5, 50))\n",
    "\n",
    "# OCSVM hyperparameters\n",
    "nu = 0.05\n",
    "gamma = 2.0\n",
    "\n",
    "# Fit the One-Class SVM\n",
    "clf = OneClassSVM(gamma=gamma, kernel=\"rbf\", nu=nu)\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_outliers = clf.predict(X_outliers)\n",
    "n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "n_error_outliers = y_pred_outliers[y_pred_outliers == 1].size\n",
    "\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the level sets of the decision function\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(\"One Class SVM\")\n",
    "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.PuBu)\n",
    "a = plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors=\"darkred\")\n",
    "plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors=\"palevioletred\")\n",
    "\n",
    "s = 20\n",
    "b1 = plt.scatter(X_train[:, 0], X_train[:, 1], c=\"white\", s=s, edgecolors=\"k\")\n",
    "b2 = plt.scatter(X_test[:, 0], X_test[:, 1], c=\"blueviolet\", s=s, edgecolors=\"k\")\n",
    "c = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c=\"gold\", s=s, edgecolors=\"k\")\n",
    "plt.axis(\"tight\")\n",
    "plt.xlim((-4.5, 4.5))\n",
    "plt.ylim((-4.5, 4.5))\n",
    "plt.legend(\n",
    "    [a.collections[0], b1, b2, c],\n",
    "    [\n",
    "        \"learned frontier\",\n",
    "        \"training observations\",\n",
    "        \"new regular observations\",\n",
    "        \"new abnormal observations\",\n",
    "    ],\n",
    "    loc=\"upper left\",\n",
    ")\n",
    "plt.xlabel(\n",
    "    \"error train: %d/%d; errors novel regular: %d/%d; errors novel abnormal: %d/%d\"\n",
    "    % (\n",
    "        n_error_train,\n",
    "        X_train.shape[0],\n",
    "        n_error_test,\n",
    "        X_test.shape[0],\n",
    "        n_error_outliers,\n",
    "        X_outliers.shape[0],\n",
    "    )\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "n_samples, n_outliers = 120, 40\n",
    "rng = np.random.RandomState(0)\n",
    "covariance = np.array([[0.5, -0.1], [0.7, 0.4]])\n",
    "cluster_1 = 0.4 * rng.randn(n_samples, 2) @ covariance + np.array([2, 2])  # general\n",
    "cluster_2 = 0.3 * rng.randn(n_samples, 2) + np.array([-2, -2])  # spherical\n",
    "outliers = rng.uniform(low=-4, high=4, size=(n_outliers, 2))\n",
    "\n",
    "X = np.concatenate([cluster_1, cluster_2, outliers])\n",
    "y = np.concatenate(\n",
    "    [np.ones((2 * n_samples), dtype=int), -np.ones((n_outliers), dtype=int)]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "scatter = plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
    "handles, labels = scatter.legend_elements()\n",
    "\n",
    "clf = IsolationForest(max_samples=100, random_state=0)\n",
    "clf.fit(X_train)\n",
    "\n",
    "\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    clf,\n",
    "    X,\n",
    "    response_method=\"predict\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "disp.ax_.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
    "disp.ax_.set_title(\"Binary decision boundary \\nof IsolationForest\")\n",
    "plt.axis(\"square\")\n",
    "plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
    "plt.show()\n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    clf,\n",
    "    X,\n",
    "    response_method=\"decision_function\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "disp.ax_.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
    "disp.ax_.set_title(\"Path length decision boundary \\nof IsolationForest\")\n",
    "plt.axis(\"square\")\n",
    "plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
    "plt.colorbar(disp.ax_.collections[1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
