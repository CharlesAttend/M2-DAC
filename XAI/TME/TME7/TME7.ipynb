{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "sU5XKbvUXSHcq2k7cg24mT",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Majeur?</th>\n",
       "      <th>Nationalite</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paris</td>\n",
       "      <td>oui</td>\n",
       "      <td>Francais</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paris</td>\n",
       "      <td>non</td>\n",
       "      <td>Francais</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Montpellier</td>\n",
       "      <td>oui</td>\n",
       "      <td>Italien</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paris</td>\n",
       "      <td>oui</td>\n",
       "      <td>Suisse</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>non</td>\n",
       "      <td>Italien</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>non</td>\n",
       "      <td>Francais</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>oui</td>\n",
       "      <td>Francais</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Montpellier</td>\n",
       "      <td>oui</td>\n",
       "      <td>Suisse</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Adresse Majeur? Nationalite  Label\n",
       "0        Paris     oui    Francais      1\n",
       "1        Paris     non    Francais     -1\n",
       "2  Montpellier     oui     Italien      1\n",
       "3        Paris     oui      Suisse     -1\n",
       "4   Strasbourg     non     Italien     -1\n",
       "5   Strasbourg     non    Francais     -1\n",
       "6   Strasbourg     oui    Francais      1\n",
       "7  Montpellier     oui      Suisse     -1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH = \".\"\n",
    "elections_data_path = f\"{PATH}/data/elections.csv\"\n",
    "\n",
    "# Séparer les caractéristiques et les étiquettes\n",
    "elections_data = pd.read_csv(elections_data_path)\n",
    "X = elections_data.drop(\"Label\", axis=1)\n",
    "y = elections_data[\"Label\"]\n",
    "\n",
    "elections_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "nbgdVeUsDTR3u0AnCbAtJW",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SymbolicDecisionTree:\n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "        self.data = None\n",
    "\n",
    "    class Node:\n",
    "        def __init__(\n",
    "            self,\n",
    "            feature=None,\n",
    "            value=None,\n",
    "            true_branch=None,\n",
    "            false_branch=None,\n",
    "            result=None,\n",
    "            entropy=None,\n",
    "        ):\n",
    "            self.feature = feature\n",
    "            self.value = value\n",
    "            self.true_branch = true_branch\n",
    "            self.false_branch = false_branch\n",
    "            self.result = result\n",
    "            self.entropy = entropy\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Combine features and labels\n",
    "        training_data = pd.concat([X, y], axis=1)\n",
    "        self.data = training_data\n",
    "        self.tree = self.build_tree(training_data)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            predictions = [\n",
    "                self.predict_single_entry(entry) for _, entry in X.iterrows()\n",
    "            ]\n",
    "        elif isinstance(X, pd.Series):\n",
    "            predictions = self.predict_single_entry(X)\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                f\"type {type(X)} not supported in predict, please implement or convert to a pandas object\"\n",
    "            )\n",
    "        return predictions\n",
    "\n",
    "    def predict_xai(self, entry):\n",
    "        explanation, _ = self.trace_tree(entry, self.tree, explanation=[])\n",
    "        return explanation\n",
    "\n",
    "    def counter_fact(self, entry):\n",
    "        explanation, _ = self.untrace_tree(entry, self.tree, explanation=[])\n",
    "        return explanation\n",
    "\n",
    "    def build_tree(self, data):\n",
    "        # If there's no data, or if all targets are the same,\n",
    "        # return a leaf node with the result\n",
    "        if len(data) == 0:\n",
    "            return self.Node()\n",
    "\n",
    "        current_uncertainty = self.gini(data.iloc[:, -1])\n",
    "        # print(data.iloc[:, -1])\n",
    "        best_gain = 0\n",
    "        best_criteria = None\n",
    "        best_sets = None\n",
    "\n",
    "        feature_count = len(data.columns) - 1  # number of attributes\n",
    "\n",
    "        for col in range(feature_count):  # for each feature\n",
    "            feature_values = data.iloc[:, col].unique()  # unique values\n",
    "            for val in feature_values:  # for each value\n",
    "                partitioned_data = self.partition(data, data.columns[col], val)\n",
    "\n",
    "                # Information gain\n",
    "                p = float(partitioned_data[0].shape[0]) / data.shape[0]\n",
    "                gain = (\n",
    "                    current_uncertainty\n",
    "                    - p * self.gini(partitioned_data[0].iloc[:, -1])\n",
    "                    - (1 - p) * self.gini(partitioned_data[1].iloc[:, -1])\n",
    "                )\n",
    "\n",
    "                if (\n",
    "                    gain > best_gain\n",
    "                    and len(partitioned_data[0]) > 0\n",
    "                    and len(partitioned_data[1]) > 0\n",
    "                ):\n",
    "                    best_gain = gain\n",
    "                    best_criteria = (data.columns[col], val)\n",
    "                    best_sets = partitioned_data\n",
    "\n",
    "        if best_gain > 0:\n",
    "            true_branch = self.build_tree(best_sets[0])\n",
    "            false_branch = self.build_tree(best_sets[1])\n",
    "            return self.Node(\n",
    "                feature=best_criteria[0],\n",
    "                value=best_criteria[1],\n",
    "                true_branch=true_branch,\n",
    "                false_branch=false_branch,\n",
    "                entropy=current_uncertainty,\n",
    "            )\n",
    "        else:\n",
    "            # We're at a leaf, determine the outcome most frequent class\n",
    "            outcome = data.iloc[:, -1].value_counts().idxmax()\n",
    "            return self.Node(result=outcome, entropy=current_uncertainty)\n",
    "\n",
    "    def predict_single_entry(self, entry):\n",
    "        node = self.tree\n",
    "        while node.result is None:\n",
    "            if entry[node.feature] == node.value:\n",
    "                node = node.true_branch\n",
    "            else:\n",
    "                node = node.false_branch\n",
    "        return node.result\n",
    "\n",
    "    def trace_tree(self, entry, node, explanation):\n",
    "        if node.result is not None:\n",
    "            return explanation, node.result\n",
    "\n",
    "        if entry[node.feature] == node.value:\n",
    "            explanation.append(f\"{node.feature} == {node.value}\")\n",
    "            return self.trace_tree(entry, node.true_branch, explanation)\n",
    "        else:\n",
    "            explanation.append(f\"{node.feature} != {node.value}\")\n",
    "            return self.trace_tree(entry, node.false_branch, explanation)\n",
    "\n",
    "    @staticmethod\n",
    "    def partition(data, feature, value):\n",
    "        true_data = data[data[feature] == value]\n",
    "        false_data = data[data[feature] != value]\n",
    "        return true_data, false_data\n",
    "\n",
    "    @staticmethod\n",
    "    def gini(labels):\n",
    "        impurity = 1\n",
    "        label_counts = Counter(labels)\n",
    "        for label in label_counts:\n",
    "            prob_of_label = label_counts[label] / float(len(labels))\n",
    "            impurity -= prob_of_label**2\n",
    "        return impurity\n",
    "\n",
    "    def display_tree(self, node=None, indent=\"\", branch=\"\"):\n",
    "        \"\"\"\n",
    "        Visualise la structure arborescente de l'arbre dans un format clair et organisé.\n",
    "\n",
    "        Format de sortie :\n",
    "        \"├──\" indique un nœud qui confirme la condition.\n",
    "        \"└──\" indique un nœud qui ne confirme pas la condition.\n",
    "        Les feuilles affichent le résultat de la classe.\n",
    "        Les nœuds internes affichent le critère de décision et son entropie.\n",
    "\n",
    "        Exemple :\n",
    "        feature_name1 == feature_value1? (Entropy = 0.1234)\n",
    "        ├── Class : Class_A\n",
    "        └── feature_name2 == feature_value2? (Entropy = 0.5678)\n",
    "            ├── Class : Class_B\n",
    "            └── Class : Class_C\n",
    "\n",
    "        Dans cet exemple :\n",
    "        - Si feature_name1 == feature_value1, l'arbre de décision le classe comme\n",
    "        'Class_A'.\n",
    "        - Sinon, il vérifie si feature_name2 == feature_value2 ; si c'est vrai, il est\n",
    "        classé comme 'Class_B', et si c'est faux, il est classé comme 'Class_C'.\n",
    "        \"\"\"\n",
    "\n",
    "        if node is None:\n",
    "            node = self.tree\n",
    "\n",
    "        # Base case: if it's a leaf node, print the result and return\n",
    "        if node.result is not None:\n",
    "            print(f\"{indent}{branch}Class: {node.result}\")\n",
    "            return\n",
    "\n",
    "        # Print the criterion for the current node\n",
    "        print(\n",
    "            f\"{indent}{branch}{node.feature} == {node.value}? (Entropy = {node.entropy:.4f})\"\n",
    "        )\n",
    "\n",
    "        # Recursive case: print the true and false branches\n",
    "        new_indent = indent + (\"│   \" if branch == \"├── \" else \"    \")\n",
    "\n",
    "        # For true branch, use '├──'\n",
    "        self.display_tree(node.true_branch, new_indent, \"├── \")\n",
    "\n",
    "        # For false branch, use '└──'\n",
    "        self.display_tree(node.false_branch, new_indent, \"└── \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "E2DTytp1Ds7XaHOozQk3Tr",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0000%\n"
     ]
    }
   ],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Initialiser et entraîner l'arbre de décision symbolique\n",
    "tree_xai = SymbolicDecisionTree()\n",
    "tree_xai.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer la précision de l'arbre de décision\n",
    "predictions = tree_xai.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "EktSxe2KwYMnX1lJfLbhjn",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of tree at -1\n",
      "End of tree at 1\n",
      "End of tree at -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('Nationalite', '!=', 'Suisse'), ('Majeur?', '!=', 'oui'), (None, -1)],\n",
       " [('Nationalite', '!=', 'Suisse'), ('Majeur?', '==', 'oui'), (None, 1)],\n",
       " [('Nationalite', '==', 'Suisse'), (None, -1)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def untrace_tree(example_class, trace_path, node, before):\n",
    "    if node.result is not None:\n",
    "        before.append((None, node.result))\n",
    "        trace_path.append(before)\n",
    "        print(f\"End of tree at {node.result}\")\n",
    "    else:\n",
    "        before_false = copy(before)\n",
    "        before_false.append((node.feature, \"!=\", node.value))\n",
    "        before_true = copy(before)\n",
    "        before_true.append((node.feature, \"==\", node.value))\n",
    "        untrace_tree(example_class, trace_path, node.false_branch, before_false)\n",
    "        untrace_tree(example_class, trace_path, node.true_branch, before_true)\n",
    "\n",
    "\n",
    "trace_path = []\n",
    "untrace_tree(1, trace_path, tree_xai.tree, [])\n",
    "trace_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "eNzQ7g4BDwvMulTAj9LBpm",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Nationalite', '!=', 'Suisse'), ('Majeur?', '!=', 'oui'), (None, -1)],\n",
       " [('Nationalite', '==', 'Suisse'), (None, -1)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_trace_path(class_to_not_keep, trace_path):\n",
    "    l = []\n",
    "    for path in trace_path:\n",
    "        end_class = path[-1][1]\n",
    "        if end_class != class_to_not_keep:\n",
    "            l.append(path)\n",
    "    return l\n",
    "\n",
    "\n",
    "filtered_trace_path = filter_trace_path(1, trace_path)\n",
    "filtered_trace_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "rmX5EaoKcNsCrIkTvdQpXt",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adresse           Paris\n",
      "Majeur?             oui\n",
      "Nationalite    Francais\n",
      "Name: 0, dtype: object\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_rules(to_explain, trace_path):\n",
    "    l = []\n",
    "    for path in trace_path:\n",
    "        n_r = 0\n",
    "        for rule in path[:-1]:\n",
    "            a, b, c = rule\n",
    "            if b == \"!=\":\n",
    "                if to_explain[a] != c:  # l'exemple valide la règle\n",
    "                    pass\n",
    "                else:  # l'exemple ne valise pas la règle\n",
    "                    n_r += 1\n",
    "            else:  # b == '=='\n",
    "                if to_explain[a] == c:  # l'exemple valide la règle\n",
    "                    pass\n",
    "                else:  # l'exemple ne valise pas la règle\n",
    "                    n_r += 1\n",
    "        l.append(n_r)\n",
    "    return np.array(l)\n",
    "\n",
    "\n",
    "sample = X.iloc[0]\n",
    "class_to_not_keep = y.iloc[0]\n",
    "print(sample)\n",
    "print(class_to_not_keep)\n",
    "filtered_trace_path = filter_trace_path(1, trace_path)\n",
    "n_r_list = count_rules(sample, filtered_trace_path)\n",
    "np.argwhere(n_r_list == np.amax(n_r_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: génération d'une base d'apprentissage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode LIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from copy import copy\n",
    "# from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "# # Nom des fonctions issus de la notation du cours\n",
    "# class CustomExplainer:\n",
    "#     def __init__(self, class_names, card_Z=10000):\n",
    "#         self.class_names = class_names\n",
    "#         self.card_Z = card_Z\n",
    "\n",
    "#     def generate_z(self, x_ref):\n",
    "#         Z = []  # list of all new exemple\n",
    "#         weights = []\n",
    "#         card_x_ref = len(x_ref)\n",
    "#         sigma = int(\n",
    "#             0.75 * np.sqrt(card_x_ref)\n",
    "#         )  # on change maximum sigma nombre de mots dans la phrase\n",
    "#         for _ in range(self.card_Z):\n",
    "#             z_i = copy(x_ref)\n",
    "#             nb_word_to_change = np.random.randint(0, sigma)\n",
    "#             index_to_remove = np.random.randint(0, card_x_ref, size=nb_word_to_change)\n",
    "#             for i in index_to_remove:\n",
    "#                 splited_text_tmp[i] = \"\"\n",
    "#             Z.append(\" \".join(splited_text_tmp))\n",
    "#             weights.append(1 - nb_word_to_change / card_x_ref)\n",
    "#         return Z, weights\n",
    "\n",
    "#     def explain_instance(self, text_instance, classifier_fn, num_features=None):\n",
    "#         modified_text_instances, weights = self.generate_z(text_instance)\n",
    "#         prob = classifier_fn(modified_text_instances).max(1)\n",
    "#         clf = Ridge(fit_intercept=True)\n",
    "#         clf.fit(\n",
    "#             self.vectorizer.transform(modified_text_instances),\n",
    "#             prob,\n",
    "#             sample_weight=weights,\n",
    "#         )\n",
    "#         return pd.Series(clf.coef_, index=vectorizer.get_feature_names_out())\n",
    "\n",
    "\n",
    "# explainer = CustomLimeTextExplainer(\n",
    "#     class_names=newsgroups_test.target_names, vectorizer=vectorizer\n",
    "# )\n",
    "# coef = explainer.explain_instance(\n",
    "#     newsgroups_test.data[idx], c.predict_proba, num_features=6\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methode LORE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "from tqdm import tqdm\n",
    "from distances import simple_match_distance\n",
    "\n",
    "\n",
    "class CustomExplainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        test_set: pd.DataFrame,\n",
    "        model,\n",
    "        distance,\n",
    "        pc=0.5,\n",
    "        pm=0.5,\n",
    "        nb_genetics=100,\n",
    "        N=1000,\n",
    "    ):\n",
    "        self.N = N\n",
    "        self.pc = pc\n",
    "        self.pm = pm\n",
    "        self.nb_genetics = nb_genetics\n",
    "        self.model = model\n",
    "        self.distance = distance\n",
    "\n",
    "        self.value_distribution = {}\n",
    "        for col in test_set.columns:\n",
    "            vc = test_set[col].value_counts(normalize=True)\n",
    "            self.value_distribution[col] = (vc.index, vc.values)\n",
    "\n",
    "    def geneticNeigh(self, x: pd.Series, same: bool):\n",
    "        if same:\n",
    "            fitness = self.fitness_same\n",
    "        else:\n",
    "            fitness = self.fitness_dif\n",
    "\n",
    "        P = pd.DataFrame([x] * self.N)  # Population init\n",
    "        M = self.evaluate(x, P, fitness)\n",
    "        top_M = np.flip(M.argsort())\n",
    "        for _ in tqdm(range(self.nb_genetics)):\n",
    "            P = P.iloc[top_M].head(self.N)\n",
    "            P = self.crossover(P)\n",
    "            P = self.mutate(P)\n",
    "\n",
    "            M = self.evaluate(x, P, fitness)\n",
    "            top_M = np.flip(M.argsort())\n",
    "        return P\n",
    "\n",
    "    def evaluate(self, x, P: pd.DataFrame, fitness):\n",
    "        x_hat = self.model.predict(x)\n",
    "        M_list = []\n",
    "        for _, z_i in P.iterrows():\n",
    "            M_list.append(fitness(x, x_hat, z_i))\n",
    "        return np.array(M_list)\n",
    "\n",
    "    def fitness_same(self, x, x_hat, z_i):\n",
    "        z_i_hat = self.model.predict(z_i)\n",
    "        return (z_i_hat == x_hat) + (1 - self.distance(x, z_i)) - ((x == z_i).all())\n",
    "\n",
    "    def fitness_dif(self, x, x_hat, z_i):\n",
    "        z_i_hat = self.model.predict(z_i)\n",
    "        return (z_i_hat != x_hat) + (1 - self.distance(x, z_i)) - ((x == z_i).all())\n",
    "\n",
    "    def mutate(\n",
    "        self,\n",
    "        P: pd.DataFrame,\n",
    "    ):\n",
    "        idx_to_mutate = np.random.randint(0, len(P), size=int(len(P) * self.pm))\n",
    "        mutations = P.iloc[idx_to_mutate].apply(self.mutate_one, axis=1)\n",
    "        P_mutated = pd.concat((mutations, P))\n",
    "        return P_mutated\n",
    "\n",
    "    def mutate_one(self, parent):\n",
    "        \"\"\"\n",
    "        Ici je fais deux mutation, il est possible d'en faire qu'une\n",
    "        Le text du diapo en fait une, mais l'image en fait deux\n",
    "        \"\"\"\n",
    "        attribute_list = parent.index\n",
    "        att_1 = np.random.choice(attribute_list)\n",
    "        att_2 = np.random.choice(attribute_list.drop(att_1))\n",
    "        children = parent.copy()\n",
    "        children[att_1] = np.random.choice(\n",
    "            self.value_distribution[att_1][0], p=self.value_distribution[att_1][1]\n",
    "        )\n",
    "        children[att_2] = np.random.choice(\n",
    "            self.value_distribution[att_2][0], p=self.value_distribution[att_2][1]\n",
    "        )\n",
    "        return children\n",
    "\n",
    "    def crossover(self, P: pd.DataFrame):\n",
    "        nb_parents = int(len(P) * self.pm)\n",
    "        idx_parents = np.random.randint(0, len(P), size=(2, nb_parents // 2))\n",
    "        crossovers = pd.concat(\n",
    "            (\n",
    "                self.crossover_one(P.iloc[idx_parents[0, i]], P.iloc[idx_parents[1, i]])\n",
    "                for i in range(nb_parents // 2)\n",
    "            )\n",
    "        )\n",
    "        P_mutated = pd.concat((crossovers, P))\n",
    "        return P_mutated\n",
    "\n",
    "    @staticmethod\n",
    "    def crossover_one(parent_1, parent_2):\n",
    "        attribute_list = parent_1.index\n",
    "        att_1 = np.random.choice(attribute_list)\n",
    "        att_2 = np.random.choice(\n",
    "            attribute_list.drop(att_1)\n",
    "        )  # on veut deux attribut différent\n",
    "        att_list = [att_1, att_2]\n",
    "\n",
    "        children_1 = parent_1.copy()\n",
    "        children_1[att_list] = parent_2[att_list]\n",
    "\n",
    "        children_2 = parent_2.copy()\n",
    "        children_2[att_list] = parent_1[att_list]\n",
    "\n",
    "        return pd.DataFrame((children_1, children_2))\n",
    "\n",
    "custom_explainer = CustomExplainer(X, tree_xai, simple_match_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:09<00:00,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "Z_true = custom_explainer.geneticNeigh(X.iloc[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:06<00:00,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "Z_false = custom_explainer.geneticNeigh(X.iloc[0], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((Z, Z_hat), axis=1).iloc[:, -1].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon c'est super lent, aussi j'ai codé comme ça me venais un peu, au pire on utilisera l'[implémentation](https://github.com/riccotti/LORE/blob/master/neighbor_generator.py) mais c'est codé differement j'crois\n",
    "\n",
    "Je sais pas c'est quoi les ordre de grandeur des hyprparamètre de l'algo génétique aussi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Majeur?</th>\n",
       "      <th>Nationalite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Montpellier</td>\n",
       "      <td>oui</td>\n",
       "      <td>Suisse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Montpellier</td>\n",
       "      <td>oui</td>\n",
       "      <td>Italien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>non</td>\n",
       "      <td>Italien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paris</td>\n",
       "      <td>oui</td>\n",
       "      <td>Suisse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>oui</td>\n",
       "      <td>Francais</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Adresse Majeur? Nationalite\n",
       "7  Montpellier     oui      Suisse\n",
       "2  Montpellier     oui     Italien\n",
       "4   Strasbourg     non     Italien\n",
       "3        Paris     oui      Suisse\n",
       "6   Strasbourg     oui    Francais"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adresse           Paris\n",
      "Majeur?             oui\n",
      "Nationalite    Francais\n",
      "Name: 0, dtype: object\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = pd.concat((Z_true, Z_false)).reset_index(drop=True)\n",
    "Z_hat = pd.Series(tree_xai.predict(Z), name=\"Label\")\n",
    "# Z, _, Z_hat, _ = train_test_split(\n",
    "#     X, y, test_size=0.01, random_state=42\n",
    "# ) # gros bricolage ici, j'arrive pas à faire passer \n",
    "# Initialiser et entraîner l'arbre de décision symbolique\n",
    "substitution_tree = SymbolicDecisionTree()\n",
    "substitution_tree.fit(Z, Z_hat)\n",
    "\n",
    "sample = X.iloc[0]\n",
    "class_to_not_keep = y.iloc[0]\n",
    "print(sample)\n",
    "print(class_to_not_keep)\n",
    "filtered_trace_path = filter_trace_path(1, trace_path)\n",
    "n_r_list = count_rules(sample, filtered_trace_path)\n",
    "np.argwhere(n_r_list == np.amax(n_r_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
