# Title page
* Explainable AI is Dead, Long Live Explainable AI!
    * Titre aguicheur, aime pas, deuxi√®me mieux
    * Hypothesis-driven Decision Support using Evaluative AI
* Papier pour aide √† la d√©cision
* Tim miller, chercheur australien, il publie sur des sujets assez vari√© en XAI
    * XAI 4 Multi agent, XAI 4 RL 
    * Humain-AI interaction
    * AI assisted d√©cision support

# Introduction
## Quick summary
* Argumente Changement paradigme XAI aide d√©cision

Framework evaluative AI :
* Centr√©e sur l'humain
* Au dela des recommandation
* En evaluant les hypoth√®se du d√©cideur
* **Mitiger Exc√®s de confiance**

## Over/Under reliance
### D√©finition
* Aide √† la d√©cision, retrouve deux ph√©nom√®nes 
* Expliquer les d√©fininions : 
    * Exc√®s de confiance : accepter les recommandations, m√™me si faux
    * Manque de confiance : inverse : rejeter les recommendation, m√™me si vrais
* == Automation bias : 
    <!-- * Biais assez important, d√®s que l'humain a un r√¥le d'observateur sur les d√©cisions des machine et qu'il reste le d√©cideur -->
    * **Pourquoi j'ai choisi ce papier**
    * La confiance excessive ‚Üí Probl√©matique
        * Au quotidient 
            * correcteur d'orthographe
            * Recrutement ; Pr√™t banquaire ect
            * Enjeux plus s√©rieux : Unit√© de soin intensif, aviation, centrale nucl√©aire
            * Algo mesure du risque de violence conjugale ‚Üí Exc√®s de confiance  ‚Üí erreur d'estimation du danger
    * Echo domaine sciences cognitives licence -> manque un peu
<!-- 3:05 ; . ;  -->

### Causes
* Manque engagement cognitif, l'esprit humain minimiser effort
* Ajout XAI qui explique
    * ~Biais de confirmation sur les explications : accepter ou rejeter

### Solutions
* Solution 1 : forcer l'engagement cognitif
    * G√©n√©ralement : forcer les gens donner d√©cision avant machine
    * Pas giga efficace
    * Pas trop appr√©ci√©
* Solution 2 : Un paradigme shift en XAI ü§îüòèüí°
    * == papier
    * => Avant parler cela -> d√©finir des crit√®res plus claire

## How we make decisions?
* naturellement : identifier option, comparer option, choisir option
* Des gens plus r√©flechis:
    * **dans notre cadre**, pour les system d'aide √† la d√©cision, r√©sum√© tout 4 points... DIAPO

## 10 cardinal decision issue
Bon system d'aide √† la d√©cision, besoin de 
* Option:  identifier, lister, r√©aliste/fesable
* Opinion & Possibilit√© : Proba et impact positif / negatif possible pour chaque options
* Compromis: comparer ce qu'on tout ce qu'on a dit au dessus
* Understand: comprendre le systeme d'aide √† la d√©cision

# Does current decision support align with those criteria?
* System actuel ?? respectent ces crit√®res
<!-- 5:30 ; . ;  -->
## No explanotory information
* Cas classique d'automatisation des d√©cisions : *d√©crire un peu*
* gens -> ignorer le system  // soit accepter des mauvaise d√©cisions
* Le d√©cideur : Calibration de la confiance uniquement sur :
    * l'accuracy du model 
    * Son exp√©rtise
* => Novice : se repose sur le systems // expert : utilise leur propre expertise 
* Mais ne coche aucune des cases
    * X identifier les autres options probable 
    * Opinion **uniquement** autour de la recommandation
    * X faire des compromis
    * X expliquabilit√©
* Mais est-ce que c'est quand m√™me utile ?? OUI 
    * D'accord -tout roule 
    * Pas d'accord -> reconsid√©rer le choix
    * -> meilleurs d√©cision
    * En pratique : non 

## With explanatory information
* Outil de XAI en plus
* Coche plus de case 
    * -> Comprendre le mod√®le 
    * -> faire des compromis : SHAP, counterfactual
    * X identifier les autres options probables
    * Jugement et possibilit√© uniquement autour de la recommandation
* => Toujours pour d√©fendre la recommandation
* Est-ce que c'est quand m√™me utile ?? OUI
    * M√™me raison que pr√©c√©dement :
        * Si pas d'accords -> regarder -> meilleurs d√©cision
    * En pratique == pas le cas
* Un model interpr√©table coche uniquement la derni√®re case 

## Cognitive for√ßing
* Cognitive forcing : d√©cideur donne d√©cision avant machine
* Coche le plus de case paradigme actuel // toujours des probl√®mes
    * d√©cideur voie plus d'option : forc√© de les chercher 
    * Toujours avec les outils XAI, on peut comprendre le mod√®le 
    * et faire des compromis par exemple avec SHAP ou les counterfactual
* -> System toujours centr√© sur sa recommandation 
* d√®s que centr√© autour de la recommandation == case partiellement coch√©
* => Sortir de ce paradigme de recommandation unique => evaluative AI

<!-- II: 8:27 -->
# The evaluative AI framework
* D√©crire : boucle, d√©cideur -> HP -> feedback
* Le paradigme est invers√© : 
    * c'est la machine qui donne son avis sur la d√©cision du *decision-maker* 
    * Et non le d√©cision maker qui donne son avis sur la d√©cision de la machine 
<!-- II: 9:09 -->

## Properties
* Exemple d'interface 
    * Potentiel m√©lanome ? 
    * Vu sur toutes les options possible 
    * int√©raction avec l'utilisateur 
    * hypoth√®se pour, hypoth√®se contre
  
## Zoom on properties
* Naturellement leur mod√®le coche toutes les cases 
* Option
    <!-- * Donne plusieurs option, sans forc√©ment dire la plus probable / leur probabilit√© 
    * Overview des possibilit√©, r√©duit un peu l'information -->
<!-- * Jugement et posibilit√© 
    * Ici c'est bien on support l'opinion du d√©cideur, 
    * Le system ne donne pas son opinion 
    * Feedback -->
* Trade-off
    * R√©ussi le mieux 
    * Pour ou contre  clair -> d√©cideur bonne overview
    * Papier :"bon d√©cideur" = personnes qui regarde les arguments qui vont contre leurs conclusions initiales 
* => extrapolation sur de l'IRL 
    * D√©cision complexe, type choix de stage, orientation
        * Regarde tous les pours et contre == bourbier 
        * // fier a l'instincs et indentifier les contre serait plus efficace
    * les discutions IRL ? 
        * Cl√© = √™tre √† l'√©coute, tourner autour de l'opinion de l'autre sans forc√©ment directement relate sur des pov personel

## Limits
* Pourquoi les gens s'engagerai avec ce system et pas les autres m√©thode 
    * Plus de controle 
    * Proche de la mani√®re dont on fait des d√©cisions (identifier, comparer, choisir)
    * X : pas de preuve de √ßa dans le papier (en psychologie √ßa serait pas pass√©, jsp pour Humain-AI interaction)
* M√©thode qui charge mentalement le d√©cideur 
    * X: toujours la moins aim√© surement 
    * Auteur se d√©fend :  quand m√™me moins d'info

## Mes critiques  
* Les crit√®res sont dur √† diff√©rencier 
    * Y'en a 10 de base, il en garde 6, 1 n'est jamais remplis, et 2 fusionne en 1 car proche (opinion et possibilit√©)
    * Des fois c'est dur de s'y retrouver, le tableau r√©sum√© est pas forc√©ment accords avec que qui est dit dans le texte, 
* Quand j'ai √©t√© voir la page wikipedia de l'automation bias, elle est assez remplis et l'autheur en parle pas du tout. Y'as pas mal d'autre facteur d√©crit et j'arrive pas √† voir pourquoi y'a pas un mot dessus dans le papier 
    * A la place l'intro parle du r√©sonnement abductif pour appuyer son mod√®le comme un mod√®le proche de la mani√®re naturel de la d√©cision
    * Alors qu'il aurait eu la place car beaucoup de r√©p√©tition dans son papier

## Mes points forts du papier
* S'attaque √† un vrais probl√®me 
* Avec une proposition forte, position pas facile √† tenir
* Pas d'exp√©rience pour appuyer l'√©valuative AI 
    * mais donne une liste exhaustive de piste de recherche dans la direction de l'√©valuative AI

# CONCLUSION
* auteur propose de changer de voix pour le XAI appliqu√© l'aide √† la d√©cision 
* Qu'il faut arreter d'expliquer les recommendation et se focus sur l'utilisateur et ces hypoth√®ses
* En se rapprochant de la mani√®re dont on prends naturellement des d√©cisions 
<!-- II: 14:42 ; 12:47 -->

---
---
---
--- Je garde pour les questions au cas o√π ---
## Differences with cognitive forcing 
* Apparament √ßa ressemblerai pas mal au technique de cognitive for√ßing 
* Les auteurs essaye plusieurs fois de se diff√©rencier √† travers le papier
* Ici la cl√© c'est que le d√©cideur est en position de contr√¥le face √† la machine, "machine in the loop"
* √©galement que √ßa suit un chemin de d√©cision plus naturelle

## Long live XAI 
* Le titre est pas vraiment clair au premi√®re abord mais il se d√©fend
* L'auteur ne veut pas se s√©parer de l'XAI ou faire une refonte
* Il veut am√©liorer une petite branche de l'XAI 
    * Evaluative AI $ \subset $ XAI 
* XAI + approche bas√© sur la recommendation sont bien et adapt√© dans certains cas 
    * Making decision at scale 
* Il faudra toujours un model recommendation based pour n'importe quelle XAI technique
* Outil de XAI existant -> d√©j√† adapt√© √† l'evaluative AI
    * Counterfactuals 
    * Feature importance (SHAP)
    * Wieghts of Evidence, case-based reasoning techniques 
<!-- II: 12:06 -->