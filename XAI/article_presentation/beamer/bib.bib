@inproceedings{evaluative-ai,
    author = {Miller, Tim},
    title = {Explainable AI is Dead, Long Live Explainable AI! Hypothesis-Driven Decision Support Using Evaluative AI},
    year = {2023},
    isbn = {9798400701924},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3593013.3594001},
    doi = {10.1145/3593013.3594001},
    abstract = {In this paper, we argue for a paradigm shift from the current model of explainable artificial intelligence (XAI), which may be counter-productive to better human decision making. In early decision support systems, we assumed that we could give people recommendations and that they would consider them, and then follow them when required. However, research found that people often ignore recommendations because they do not trust them; or perhaps even worse, people follow them blindly, even when the recommendations are wrong. Explainable artificial intelligence mitigates this by helping people to understand how and why models give certain recommendations. However, recent research shows that people do not always engage with explainability tools enough to help improve decision making. The assumption that people will engage with recommendations and explanations has proven to be unfounded. We argue this is because we have failed to account for two things. First, recommendations (and their explanations) take control from human decision makers, limiting their agency. Second, giving recommendations and explanations does not align with the cognitive processes employed by people making decisions. This position paper proposes a new conceptual framework called Evaluative AI for explainable decision support. This is a machine-in-the-loop paradigm in which decision support tools provide evidence for and against decisions made by people, rather than provide recommendations to accept or reject. We argue that this mitigates issues of over- and under-reliance on decision support tools, and better leverages human expertise in decision making.},
    booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
    pages = {333-342},
    numpages = {10},
    location = {Chicago, IL, USA},
    series = {FAccT '23}
}

@incollection{evidence-based-decision-management,
    author = {Yates, J. Frank and Potworowski, Georges A.},
    isbn = {9780199763986},
    title = "{198 Evidence-Based Decision Management}",
    booktitle = "{The Oxford Handbook of Evidence-Based Management}",
    publisher = {Oxford University Press},
    year = {2012},
    month = {06},
    abstract = "{ Decision making is the lifeblood of every organization and the central focus in the practice of evidence-based management (EBMgt). To help guide the practice of EBMgt, this chapter describes fundamental concepts of decision making and decision management. It begins with a discussion of the features that distinguish decision making from other, related concepts, such as more general problem solving and judgment. It then describes how crucial aspects of decision management are approached especially effectively when decision processes are broken down into essential elements. It then describes the theory known as the “cardinal decision issue perspective,” and illustrates its use as a decision management tool.}",
    doi = {10.1093/oxfordhb/9780199763986.013.0012},
    url = {https://doi.org/10.1093/oxfordhb/9780199763986.013.0012},
    eprint = {https://academic.oup.com/book/0/chapter/318650807/chapter-ag-pdf/44492988/book\_36314\_section\_318650807.ag.pdf},
}


