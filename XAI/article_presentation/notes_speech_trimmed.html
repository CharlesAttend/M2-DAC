<!DOCTYPE html>
<html>
<head>
<title>notes_speech_trimmed.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="title-page">Title page</h1>
<ul>
<li>Explainable AI is Dead, Long Live Explainable AI!
<ul>
<li>Titre aguicheur, aime pas, deuxi√®me mieux</li>
<li>Hypothesis-driven Decision Support using Evaluative AI</li>
</ul>
</li>
<li>Papier pour aide √† la d√©cision</li>
<li>Tim miller, chercheur australien, il publie sur des sujets assez vari√© en XAI
<ul>
<li>XAI 4 Multi agent, XAI 4 RL</li>
<li>Humain-AI interaction</li>
<li>AI assisted d√©cision support</li>
</ul>
</li>
</ul>
<h1 id="introduction">Introduction</h1>
<h2 id="quick-summary">Quick summary</h2>
<ul>
<li>Argumente Changement paradigme XAI aide d√©cision</li>
</ul>
<p>Framework evaluative AI :</p>
<ul>
<li>Centr√©e sur l'humain</li>
<li>Au dela des recommandation</li>
<li>En evaluant les hypoth√®se du d√©cideur</li>
<li><strong>Mitiger Exc√®s de confiance</strong></li>
</ul>
<h2 id="overunder-reliance">Over/Under reliance</h2>
<h3 id="d%C3%A9finition">D√©finition</h3>
<ul>
<li>Aide √† la d√©cision, retrouve deux ph√©nom√®nes</li>
<li>Expliquer les d√©fininions :
<ul>
<li>Exc√®s de confiance : accepter les recommandations, m√™me si faux</li>
<li>Manque de confiance : inverse : rejeter les recommendation, m√™me si vrais</li>
</ul>
</li>
<li>== Automation bias :  <!-- * Biais assez important, d√®s que l'humain a un r√¥le d'observateur sur les d√©cisions des machine et qu'il reste le d√©cideur -->
<ul>
<li><strong>Pourquoi j'ai choisi ce papier</strong></li>
<li>La confiance excessive ‚Üí Probl√©matique
<ul>
<li>Au quotidient
<ul>
<li>correcteur d'orthographe</li>
<li>Recrutement ; Pr√™t banquaire ect</li>
<li>Enjeux plus s√©rieux : Unit√© de soin intensif, aviation, centrale nucl√©aire</li>
<li>Algo mesure du risque de violence conjugale ‚Üí Exc√®s de confiance  ‚Üí erreur d'estimation du danger</li>
</ul>
</li>
</ul>
</li>
<li>Echo domaine sciences cognitives licence -&gt; manque un peu</li>
</ul>
</li>
</ul>
<!-- 3:05 ; . ;  -->
<h3 id="causes">Causes</h3>
<ul>
<li>Manque engagement cognitif, l'esprit humain minimiser effort</li>
<li>Ajout XAI qui explique
<ul>
<li>~Biais de confirmation sur les explications : accepter ou rejeter</li>
</ul>
</li>
</ul>
<h3 id="solutions">Solutions</h3>
<ul>
<li>Solution 1 : forcer l'engagement cognitif
<ul>
<li>G√©n√©ralement : forcer les gens donner d√©cision avant machine</li>
<li>Pas giga efficace</li>
<li>Pas trop appr√©ci√©</li>
</ul>
</li>
<li>Solution 2 : Un paradigme shift en XAI ü§îüòèüí°
<ul>
<li>== papier</li>
<li>=&gt; Avant parler cela -&gt; d√©finir des crit√®res plus claire</li>
</ul>
</li>
</ul>
<h2 id="how-we-make-decisions">How we make decisions?</h2>
<ul>
<li>naturellement : identifier option, comparer option, choisir option</li>
<li>Des gens plus r√©flechis:
<ul>
<li><strong>dans notre cadre</strong>, pour les system d'aide √† la d√©cision, r√©sum√© tout 4 points... DIAPO</li>
</ul>
</li>
</ul>
<h2 id="10-cardinal-decision-issue">10 cardinal decision issue</h2>
<p>Bon system d'aide √† la d√©cision, besoin de</p>
<ul>
<li>Option:  identifier, lister, r√©aliste/fesable</li>
<li>Opinion &amp; Possibilit√© : Proba et impact positif / negatif possible pour chaque options</li>
<li>Compromis: comparer ce qu'on tout ce qu'on a dit au dessus</li>
<li>Understand: comprendre le systeme d'aide √† la d√©cision</li>
</ul>
<h1 id="does-current-decision-support-align-with-those-criteria">Does current decision support align with those criteria?</h1>
<ul>
<li>System actuel ?? respectent ces crit√®res</li>
</ul>
<!-- 5:30 ; . ;  -->
<h2 id="no-explanotory-information">No explanotory information</h2>
<ul>
<li>Cas classique d'automatisation des d√©cisions : <em>d√©crire un peu</em></li>
<li>gens -&gt; ignorer le system  // soit accepter des mauvaise d√©cisions</li>
<li>Le d√©cideur : Calibration de la confiance uniquement sur :
<ul>
<li>l'accuracy du model</li>
<li>Son exp√©rtise</li>
</ul>
</li>
<li>=&gt; Novice : se repose sur le systems // expert : utilise leur propre expertise</li>
<li>Mais ne coche aucune des cases
<ul>
<li>X identifier les autres options probable</li>
<li>Opinion <strong>uniquement</strong> autour de la recommandation</li>
<li>X faire des compromis</li>
<li>X expliquabilit√©</li>
</ul>
</li>
<li>Mais est-ce que c'est quand m√™me utile ?? OUI
<ul>
<li>D'accord -tout roule</li>
<li>Pas d'accord -&gt; reconsid√©rer le choix</li>
<li>-&gt; meilleurs d√©cision</li>
<li>En pratique : non</li>
</ul>
</li>
</ul>
<h2 id="with-explanatory-information">With explanatory information</h2>
<ul>
<li>Outil de XAI en plus</li>
<li>Coche plus de case
<ul>
<li>-&gt; Comprendre le mod√®le</li>
<li>-&gt; faire des compromis : SHAP, counterfactual</li>
<li>X identifier les autres options probables</li>
<li>Jugement et possibilit√© uniquement autour de la recommandation</li>
</ul>
</li>
<li>=&gt; Toujours pour d√©fendre la recommandation</li>
<li>Est-ce que c'est quand m√™me utile ?? OUI
<ul>
<li>M√™me raison que pr√©c√©dement :
<ul>
<li>Si pas d'accords -&gt; regarder -&gt; meilleurs d√©cision</li>
</ul>
</li>
<li>En pratique == pas le cas</li>
</ul>
</li>
<li>Un model interpr√©table coche uniquement la derni√®re case</li>
</ul>
<h2 id="cognitive-for%C3%A7ing">Cognitive for√ßing</h2>
<ul>
<li>Cognitive forcing : d√©cideur donne d√©cision avant machine</li>
<li>Coche le plus de case paradigme actuel // toujours des probl√®mes
<ul>
<li>d√©cideur voie plus d'option : forc√© de les chercher</li>
<li>Toujours avec les outils XAI, on peut comprendre le mod√®le</li>
<li>et faire des compromis par exemple avec SHAP ou les counterfactual</li>
</ul>
</li>
<li>-&gt; System toujours centr√© sur sa recommandation</li>
<li>d√®s que centr√© autour de la recommandation == case partiellement coch√©</li>
<li>=&gt; Sortir de ce paradigme de recommandation unique =&gt; evaluative AI</li>
</ul>
<!-- II: 8:27 -->
<h1 id="the-evaluative-ai-framework">The evaluative AI framework</h1>
<ul>
<li>D√©crire : boucle, d√©cideur -&gt; HP -&gt; feedback</li>
<li>Le paradigme est invers√© :
<ul>
<li>c'est la machine qui donne son avis sur la d√©cision du <em>decision-maker</em></li>
<li>Et non le d√©cision maker qui donne son avis sur la d√©cision de la machine</li>
</ul>
</li>
</ul>
<!-- II: 9:09 -->
<h2 id="properties">Properties</h2>
<ul>
<li>Exemple d'interface
<ul>
<li>Potentiel m√©lanome ?</li>
<li>Vu sur toutes les options possible</li>
<li>int√©raction avec l'utilisateur</li>
<li>hypoth√®se pour, hypoth√®se contre</li>
</ul>
</li>
</ul>
<h2 id="zoom-on-properties">Zoom on properties</h2>
<ul>
<li>Naturellement leur mod√®le coche toutes les cases</li>
<li>Option  <!-- * Donne plusieurs option, sans forc√©ment dire la plus probable / leur probabilit√© 
  * Overview des possibilit√©, r√©duit un peu l'information -->
</li>
</ul>
<!-- * Jugement et posibilit√© 
    * Ici c'est bien on support l'opinion du d√©cideur, 
    * Le system ne donne pas son opinion 
    * Feedback -->
<ul>
<li>Trade-off
<ul>
<li>R√©ussi le mieux</li>
<li>Pour ou contre  clair -&gt; d√©cideur bonne overview</li>
<li>Papier :&quot;bon d√©cideur&quot; = personnes qui regarde les arguments qui vont contre leurs conclusions initiales</li>
</ul>
</li>
<li>=&gt; extrapolation sur de l'IRL
<ul>
<li>D√©cision complexe, type choix de stage, orientation
<ul>
<li>Regarde tous les pours et contre == bourbier</li>
<li>// fier a l'instincs et indentifier les contre serait plus efficace</li>
</ul>
</li>
<li>les discutions IRL ?
<ul>
<li>Cl√© = √™tre √† l'√©coute, tourner autour de l'opinion de l'autre sans forc√©ment directement relate sur des pov personel</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="limits">Limits</h2>
<ul>
<li>Pourquoi les gens s'engagerai avec ce system et pas les autres m√©thode
<ul>
<li>Plus de controle</li>
<li>Proche de la mani√®re dont on fait des d√©cisions (identifier, comparer, choisir)</li>
<li>X : pas de preuve de √ßa dans le papier (en psychologie √ßa serait pas pass√©, jsp pour Humain-AI interaction)</li>
</ul>
</li>
<li>M√©thode qui charge mentalement le d√©cideur
<ul>
<li>X: toujours la moins aim√© surement</li>
<li>Auteur se d√©fend :  quand m√™me moins d'info</li>
</ul>
</li>
</ul>
<h2 id="mes-critiques">Mes critiques</h2>
<ul>
<li>Les crit√®res sont dur √† diff√©rencier
<ul>
<li>Y'en a 10 de base, il en garde 6, 1 n'est jamais remplis, et 2 fusionne en 1 car proche (opinion et possibilit√©)</li>
<li>Des fois c'est dur de s'y retrouver, le tableau r√©sum√© est pas forc√©ment accords avec que qui est dit dans le texte,</li>
</ul>
</li>
<li>Quand j'ai √©t√© voir la page wikipedia de l'automation bias, elle est assez remplis et l'autheur en parle pas du tout. Y'as pas mal d'autre facteur d√©crit et j'arrive pas √† voir pourquoi y'a pas un mot dessus dans le papier
<ul>
<li>A la place l'intro parle du r√©sonnement abductif pour appuyer son mod√®le comme un mod√®le proche de la mani√®re naturel de la d√©cision</li>
<li>Alors qu'il aurait eu la place car beaucoup de r√©p√©tition dans son papier</li>
</ul>
</li>
</ul>
<h2 id="mes-points-forts-du-papier">Mes points forts du papier</h2>
<ul>
<li>S'attaque √† un vrais probl√®me</li>
<li>Avec une proposition forte, position pas facile √† tenir</li>
<li>Pas d'exp√©rience pour appuyer l'√©valuative AI
<ul>
<li>mais donne une liste exhaustive de piste de recherche dans la direction de l'√©valuative AI</li>
</ul>
</li>
</ul>
<h1 id="conclusion">CONCLUSION</h1>
<ul>
<li>auteur propose de changer de voix pour le XAI appliqu√© l'aide √† la d√©cision</li>
<li>Qu'il faut arreter d'expliquer les recommendation et se focus sur l'utilisateur et ces hypoth√®ses</li>
<li>En se rapprochant de la mani√®re dont on prends naturellement des d√©cisions</li>
</ul>
<!-- II: 14:42 ; 12:47 -->
<hr>
<hr>
<hr>
<p>--- Je garde pour les questions au cas o√π ---</p>
<h2 id="differences-with-cognitive-forcing">Differences with cognitive forcing</h2>
<ul>
<li>Apparament √ßa ressemblerai pas mal au technique de cognitive for√ßing</li>
<li>Les auteurs essaye plusieurs fois de se diff√©rencier √† travers le papier</li>
<li>Ici la cl√© c'est que le d√©cideur est en position de contr√¥le face √† la machine, &quot;machine in the loop&quot;</li>
<li>√©galement que √ßa suit un chemin de d√©cision plus naturelle</li>
</ul>
<h2 id="long-live-xai">Long live XAI</h2>
<ul>
<li>Le titre est pas vraiment clair au premi√®re abord mais il se d√©fend</li>
<li>L'auteur ne veut pas se s√©parer de l'XAI ou faire une refonte</li>
<li>Il veut am√©liorer une petite branche de l'XAI
<ul>
<li>Evaluative AI $ \subset $ XAI</li>
</ul>
</li>
<li>XAI + approche bas√© sur la recommendation sont bien et adapt√© dans certains cas
<ul>
<li>Making decision at scale</li>
</ul>
</li>
<li>Il faudra toujours un model recommendation based pour n'importe quelle XAI technique</li>
<li>Outil de XAI existant -&gt; d√©j√† adapt√© √† l'evaluative AI
<ul>
<li>Counterfactuals</li>
<li>Feature importance (SHAP)</li>
<li>Wieghts of Evidence, case-based reasoning techniques</li>
</ul>
</li>
</ul>
<!-- II: 12:06 -->
</body>
</html>
